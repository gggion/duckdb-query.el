#+title: duckdb-query.el - Query Anything, Get Elisp
#+options: toc:nil

Query remote Parquet files, local CSVs, org-mode tables, and Elisp data
structures with SQL. Get results as native Elisp values. One function call, no
intermediate files, no external scripts.

#+begin_html
<table align="center"><tr>
    <th width="700px">Query Remote Data, Filter with Elisp, Get Native Structures</th></tr>
<tr><td>

<p><strong>Query joining 336k-row remote Parquet with Elisp alist:</strong></p>
<pre lang="elisp">(let ((carriers '(((code . "UA") (name . "United Airlines"))
                  ((code . "AA") (name . "American Airlines"))
                  ((code . "DL") (name . "Delta Air Lines")))))
  (duckdb-query
   "SELECT c.name as airline,
           {'flights': COUNT(*),
            'avg_delay': ROUND(AVG(f.arr_delay), 1)} as stats
    FROM 'https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet' f
    JOIN @carriers c ON f.carrier = c.code
    GROUP BY c.name
    ORDER BY COUNT(*) DESC"
   :data `((carriers . ,carriers))
   :format :columnar))</pre>

<p><strong>Result (columnar format with nested structs):</strong></p>
<pre lang="elisp">((airline . ["United Airlines" "Delta Air Lines" "American Airlines"])
 (stats . [((flights . 58665) (avg_delay . 3.6))
           ((flights . 48110) (avg_delay . 1.6))
           ((flights . 32729) (avg_delay . 0.4))]))</pre>
</td></tr></table>
<p align="center"><em>One function call: remote Parquet + Elisp filter → nested Elisp structures</em></p>
#+end_html

DuckDB is an embedded analytical database that reads Parquet, CSV, and JSON
directly from local paths, HTTP URLs, or cloud storage. This package makes
DuckDB's capabilities available to Elisp programs. The ~duckdb-query~ function
executes SQL and returns alists, plists, vectors, or org-table-compatible lists.
Results are ready for ~mapcar~, ~seq-filter~, ~cl-loop~, or direct insertion
into buffers.

The package treats all data sources uniformly. Elisp alists become SQL tables
via the ~:data~ parameter. Named org tables in your buffer resolve through
~@org:table-name~ syntax. These combine freely with file paths and URLs in
joins, unions, and subqueries. A query can join a remote Parquet file with a
ten-row org table and a runtime Elisp variable, returning the result as an
alist you can immediately process.

* COMMENT README
# ================

=This commented out treee is for usage inside of emacs=
=without all the html getting in the way=

# ================

#+begin_src elisp :results code
(let ((carriers '(((code . "UA") (name . "United Airlines"))
                  ((code . "AA") (name . "American Airlines"))
                  ((code . "DL") (name . "Delta Air Lines")))))
  (duckdb-query
   "SELECT c.name as airline,
           {'flights': COUNT(*),
            'avg_delay': ROUND(AVG(f.arr_delay), 1)} as stats
    FROM 'https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet' f
    JOIN @carriers c ON f.carrier = c.code
    GROUP BY c.name
    ORDER BY COUNT(*) DESC"
   :data `((carriers . ,carriers))
   :format :columnar))
#+end_src

#+RESULTS:
#+begin_src elisp
((airline . ["United Airlines" "Delta Air Lines" "American Airlines"])
 (stats
  . [((flights . 58665) (avg_delay . 3.6)) ((flights . 48110) (avg_delay . 1.6))
     ((flights . 32729) (avg_delay . 0.4))]))
#+end_src

** COMMENT  Quick Examples

#+begin_src elisp :results code
(duckdb-query
 "SELECT 'Alice' as name, 95 as score
  UNION ALL SELECT 'Bob', 87")
#+end_src

#+RESULTS:
#+begin_src elisp
(((name . "Alice") (score . 95)) ((name . "Bob") (score . 87)))
#+end_src

#+begin_src elisp :results code
(duckdb-query
 "SELECT * FROM range(1,4) t(n),
   (SELECT unnest(['a','b']) as letter)"
 :format :org-table)
#+end_src

#+RESULTS:
#+begin_src elisp
((n letter) (1 "a") (2 "a") (3 "a") (1 "b") (2 "b") (3 "b"))
#+end_src

#+begin_src elisp :results code
(duckdb-query-value
 "SELECT COUNT(*) FROM range(1000)")
#+end_src

#+RESULTS:
#+begin_src elisp
1000
#+end_src

#+begin_src elisp :results code
(duckdb-query-column "SELECT unnest(['red','green','blue']) as color")
#+end_src

#+RESULTS:
#+begin_src elisp
("red" "green" "blue")
#+end_src

#+begin_src elisp :results code
(duckdb-query
 "SELECT * FROM range(5) t(n)"
 :format :columnar)
#+end_src

#+RESULTS:
#+begin_src elisp
((n . [0 1 2 3 4]))
#+end_src

** COMMENT  Querying Elisp Data

Pass Elisp alists to queries via the ~:data~ parameter. The data becomes a table
named ~@data~:

#+begin_src elisp :results code
(duckdb-query
 "SELECT name, score * 1.1 as curved
  FROM @data
  WHERE score > 85"
 :data '(((name . "Aly") (score . 95))
         ((name . "Bob") (score . 87))
         ((name . "Carol") (score . 72))))
#+end_src

#+RESULTS:
#+begin_src elisp
(((name . "Aly") (curved . 104.5)) ((name . "Bob") (curved . 95.7)))
#+end_src

For multiple tables, use named bindings with backquote to capture lexical
variables:

#+begin_src elisp :results code
(let ((users ;; users table
       '(((id . 1) (name . "Alice"))
         ((id . 2) (name . "Bob"))))
      (orders ;; orders table
       '(((user_id . 1) (item . "Widget"))
         ((user_id . 2) (item . "Gadget"))
         ((user_id . 1) (item . "Gizmo")))))
  (duckdb-query
   "SELECT u.name, COUNT(*) as count
    FROM @users u
    JOIN @orders o ON u.id = o.user_id
    GROUP BY u.name"
   :data `((users . ,users)
           (orders . ,orders))))
#+end_src

#+RESULTS:
#+begin_src elisp
(((name . "Alice") (count . 2)) ((name . "Bob") (count . 1)))
#+end_src

This enables joining runtime Elisp state with static file data. Previously this
required exporting to CSV, running an external query, and parsing results. Now
it is one expression.

** COMMENT Querying Org Tables

Reference named org tables with ~@org:table-name~. Given this table in your
buffer:

#+NAME: inventory
| sku   | product | stock | price |
|-------+---------+-------+-------|
| A-100 | Widget  |    50 |  9.99 |
| B-200 | Gadget  |    30 | 24.99 |
| C-300 | Gizmo   |    75 | 14.99 |

#+begin_src elisp :results code
(duckdb-query
 "SELECT product,
    stock * price as value
  FROM @org:inventory
  ORDER BY value DESC"
 :format :org-table)
#+end_src

Reference tables in other files with ~@org:path/to/file.org:table-name~.

** COMMENT  Combining Sources

Join an org table with Elisp data:
#+begin_src elisp :results code
(let ((sales '(((sku . "A-100") (qty . 10))
               ((sku . "A-100") (qty . 5))
               ((sku . "C-300") (qty . 20)))))
  (duckdb-query
   "SELECT i.product,
           SUM(s.qty) as sold,
           i.stock - SUM(s.qty) as remaining
    FROM @org:inventory i
    JOIN @sales s ON i.sku = s.sku
    GROUP BY i.product, i.stock"
   :data `((sales . ,sales))))
#+end_src

Join a remote Parquet file with local Elisp configuration:
#+begin_src elisp :results code
 (let ((airports '(((code . "JFK")
                   (name . "JFK International"))
                  ((code . "LGA")
                   (name . "LaGuardia")))))
  (duckdb-query
   "SELECT a.name,
           COUNT(*) as departures,
           ROUND(AVG(f.dep_delay), 1) as avg_delay
    FROM 'https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet' as f
    JOIN @airports a ON f.origin = a.code
    GROUP BY a.name
    ORDER BY departures DESC"
   :data `((airports . ,airports))))

;; => (((name . "JFK International") (departures . 111279) (avg_delay . 12.1))
;;     ((name . "LaGuardia") (departures . 104662) (avg_delay . 10.3)))
#+end_src

#+RESULTS:
#+begin_src elisp
(((name . "JFK International") (departures . 111279) (avg_delay . 12.1))
 ((name . "LaGuardia") (departures . 104662) (avg_delay . 10.3)))
#+end_src

** COMMENT  Output Formats

The ~:format~ parameter controls result structure:

| Format       | Structure                 | Use Case                      |
|--------------+---------------------------+-------------------------------|
| ~:alist~     | List of alists            | General Elisp processing      |
| ~:plist~     | List of plists            | Keyword-based access          |
| ~:hash~      | List of hash-tables       | O(1) field lookup             |
| ~:vector~    | Vector of alists          | Index-based access            |
| ~:columnar~  | Alist of column vectors   | Numerical analysis            |
| ~:org-table~ | List of lists with header | Display, org-mode integration |
| ~:raw~       | JSON string               | Custom parsing                |

** COMMENT  Schema Introspection
Discover structure before querying:

#+begin_src elisp :results code :exports both
(duckdb-query-column-types "SELECT 1 as id, 'text' as name, 3.14 as value")
;; => (("id" . "INTEGER") ("name" . "VARCHAR") ("value" . "DECIMAL(3,2)"))
#+end_src

#+begin_src elisp :results code :exports both
(duckdb-query-columns
 "https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet")

;; => ("year" "month" "day" "dep_time" "sched_dep_time" "dep_delay" "arr_time"
;;     "sched_arr_time" "arr_delay" "carrier" "flight" "tailnum" "origin" "dest"
;;     "air_time" "distance" "hour" "minute" "time_hour")
#+end_src

** COMMENT  Database Persistence
For workflows requiring state across queries, bind a database file:

#+begin_src elisp :results code
(duckdb-with-transient-database
  (duckdb-query
   "CREATE TABLE events (id INT, name TEXT)"
   :readonly nil)
  (duckdb-query
   "INSERT INTO events VALUES
    (1, 'click'), (2, 'scroll')"
   :readonly nil)
  (duckdb-query "SELECT * FROM events"))
#+end_src

#+RESULTS:
#+begin_src elisp
(((id . 1) (name . "click")) ((id . 2) (name . "scroll")))
#+end_src


~duckdb-with-transient-database~ creates a temporary file deleted after the
block. Use ~duckdb-with-database~ for persistent files:

#+begin_src elisp :results code
(duckdb-with-database "analytics.duckdb"
  (duckdb-query "SELECT COUNT(*) FROM events"))
#+end_src

** COMMENT  Nested Types

DuckDB supports STRUCT, LIST, MAP, and ARRAY types. These serialize correctly as
nested Elisp structures:

#+begin_src elisp :results code
(duckdb-query
 "SELECT
    {'x': 1, 'y': 2}::STRUCT(x INT, y INT)
    as point")
#+end_src

#+RESULTS:
#+begin_src elisp
(((point (x . 1) (y . 2))))
#+end_src

#+begin_src elisp :results code
;; Nested data survives roundtrips
(let ((data
       '(((id . 1) (loc (x . 10) (y . 20)))
         ((id . 2) (loc (x . 30) (y . 40))))))
  (duckdb-query
   "SELECT id, loc.x + loc.y as sum
    FROM @data"
   :data data))
#+end_src

#+RESULTS:
#+begin_src elisp
(((id . 1) (sum . 30)) ((id . 2) (sum . 70)))
#+end_src

** COMMENT  Performance

The package writes results to temporary files by default, providing 3-5x speedup
on large results compared to streaming through stdout:

: | Result Size | Default (file) | Streaming (pipe) | Speedup |
: |-------------+----------------+------------------+---------|
: | 10k rows    | 64ms           | 162ms            | 2.5x    |
: | 100k rows   | 366ms          | 1.28s            | 3.5x    |
: | 500k rows   | 1.32s          | 6.19s            | 4.7x    |

Force streaming mode with ~:output-via :pipe~ when needed. DDL statements
automatically use streaming since they cannot be wrapped in file output.

Profile your specific queries with the benchmark module:

#+begin_src elisp
(duckdb-query-bench-output-strategies
 "SELECT * FROM range(10000) t(i)"
 :iterations 3)
#+end_src

#+RESULTS:
| strategy | mean    | min     | max     | n |
| :file    | 20.62ms | 20.12ms | 21.52ms | 3 |
| :pipe    | 20.84ms | 20.50ms | 21.42ms | 3 |
| :speedup | 1.01x   |         |         |   |

Other benchmark functions: ~duckdb-query-bench-formats~ (compare output formats),
~duckdb-query-bench-nested-types~ (compare nested type handling),
~duckdb-query-bench-data-formats~ (compare ~:data~ serialization).

** COMMENT  Acknowledgements

- [[https://github.com/ak-coram/cl-duckdb][cl-duckdb]] by Ákos Kiss: The Common Lisp DuckDB wrapper that inspired this
  package's design philosophy. The approach of treating query results as native
  Lisp data structures, the ~with-static-table~ pattern for querying Lisp data
  directly, and the ~with-transient-connection~ / ~with-default-connection~
  macros for database context management all informed the design of
  duckdb-query's ~:data~ parameter, ~@org:~ references, and
  ~duckdb-with-transient-database~ / ~duckdb-with-database~ forms.

** COMMENT  Related Packages
- [[https://github.com/jhinch/ob-duckdb][ob-duckdb]]: Org Babel integration for DuckDB source blocks. SOON I'll add most
  of the functionalities here to it via a specialized ob-duckdb-query executor,
  this will allow org-table reference in duckdb-sql source blocks and new output
  types.


* Quick Examples
#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">;; List of alists (default)
(duckdb-query
 "SELECT 'Alice' as name, 95 as score
  UNION ALL SELECT 'Bob', 87")</pre>
</td><td>
<pre lang="elisp">(((name . "Alice") (score . 95))
 ((name . "Bob") (score . 87)))</pre>
</td></tr>

<!-- spacing -->
<tr></tr>

<tr><td>
<pre lang="elisp">;; Org-table format for display
(duckdb-query
 "SELECT * FROM range(1,4) t(n),
   (SELECT unnest(['a','b']) as letter)"
 :format :org-table)</pre>
</td><td>
<pre>
,  rendered       data
,| n | letter | ((n letter)
,|---|--------|  (1 "a") (2 "a")
,| 1 | a      |  (3 "a") (1 "b")
,| 1 | b      |  (2 "b") (3 "b"))
,| 2 | a      |
,| 2 | b      |
,| 3 | a      |
,| 3 | b      |
</pre>
</td></tr>

<!-- spacing -->
<tr></tr>

<tr><td>
<pre lang="elisp">;; Single value extraction
(duckdb-query-value
 "SELECT COUNT(*) FROM range(1000)")</pre>
</td><td>
<pre lang="elisp">1000</pre>
</td></tr>

<!-- spacing -->
<tr></tr>

<tr><td>
<pre lang="elisp">;; Single column as list
(duckdb-query-column
 "SELECT unnest(
 ['red','green','blue']) as color")</pre>
</td><td>
<pre lang="elisp">("red" "green" "blue")</pre>
</td></tr>

<!-- spacing -->
<tr></tr>

<tr><td>
<pre lang="elisp">;; Columnar format for analysis
(duckdb-query
 "SELECT * FROM range(5) t(n)"
 :format :columnar)</pre>
</td><td>
<pre lang="elisp">((n . [0 1 2 3 4]))</pre>
</td></tr></table>
#+end_html
* Contents :noexport:
:PROPERTIES:
:TOC:      :include siblings :depth 1 :ignore this
:END:
:CONTENTS:
- [[#querying-elisp-data][Querying Elisp Data]]
- [[#querying-org-tables][Querying Org Tables]]
- [[#combining-sources][Combining Sources]]
- [[#output-formats][Output Formats]]
- [[#schema-introspection][Schema Introspection]]
- [[#database-persistence][Database Persistence]]
- [[#new-session-based-execution][(NEW) Session-Based Execution]]
- [[#nested-types][Nested Types]]
- [[#performance][Performance]]
- [[#acknowledgements][Acknowledgements]]
- [[#related-packages][Related Packages]]
- [[#integration][Integration]]
:END:

* Querying Elisp Data
:PROPERTIES:
:CUSTOM_ID: querying-elisp-data
:END:

Pass Elisp alists to queries via the ~:data~ parameter. The data becomes a table
named ~@data~:

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">(duckdb-query
 "SELECT name, score * 1.1 as curved
  FROM @data
  WHERE score > 85"
 :data '(((name . "Aly") (score . 95))
         ((name . "Bob") (score . 87))
         ((name . "Carol") (score . 72))))</pre>
</td><td>
<pre lang="elisp">(((name . "Aly") (curved . 104.5))
 ((name . "Bob") (curved . 95.7)))</pre>
</td></tr></table>
#+end_html

For multiple tables, use named bindings with backquote to capture lexical
variables:

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp"> (let ((users ;; users table
       '(((id . 1) (name . "Alice"))
         ((id . 2) (name . "Bob"))))
      (orders ;; orders table
       '(((user_id . 1) (item . "Widget"))
         ((user_id . 2) (item . "Gadget"))
         ((user_id . 1) (item . "Gizmo")))))
  (duckdb-query
   "SELECT u.name, COUNT(*) as count
    FROM @users u
    JOIN @orders o ON u.id = o.user_id
    GROUP BY u.name"
   :data `((users . ,users)
           (orders . ,orders))))</pre>
</td><td>
<pre lang="elisp">
(((name . "Alice") (count . 2))
 ((name . "Bob") (count . 1)))
</pre>
</td></tr></table>
#+end_html

This enables joining runtime Elisp state with static file data. Previously this
required exporting to CSV, running an external query, and parsing results. Now
it is one expression.

* Querying Org Tables
:PROPERTIES:
:CUSTOM_ID: querying-org-tables
:END:

Reference named org tables with ~@org:table-name~. Given this table in your
buffer:

#+begin_html
<table align="center"><tr>
    <th width="500px">Table</th>
<tr><td align="center">
<pre>
,#+NAME: inventory
,| sku   | product | stock | price |
,|-------+---------+-------+-------|
,| A-100 | Widget  |    50 |  9.99 |
,| B-200 | Gadget  |    30 | 24.99 |
,| C-300 | Gizmo   |    75 | 14.99 |
</pre>
</td></tr></table>
#+end_html

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">(duckdb-query
 "SELECT product,
    stock * price as value
  FROM @org:inventory
  ORDER BY value DESC"
 :format :org-table)</pre>
</td><td>
<pre>
,| product |   value | ((product value)
,|---------+---------|  ("Gizmo" 1124.25)
,| Gizmo   | 1124.25 |  ("Gadget" 749.7)
,| Gadget  |   749.7 |  ("Widget" 499.5))
,| Widget  |   499.5 |
</pre>
</td></tr></table>
#+end_html

Reference tables in other files with ~@org:path/to/file.org:table-name~.

* Combining Sources
:PROPERTIES:
:CUSTOM_ID: combining-sources
:END:

Join an org table with Elisp data:

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">(let ((sales '(((sku . "A-100") (qty . 10))
               ((sku . "A-100") (qty . 5))
               ((sku . "C-300") (qty . 20)))))
  (duckdb-query
   "SELECT i.product,
           SUM(s.qty) as sold,
           i.stock - SUM(s.qty) as remaining
    FROM @org:inventory i
    JOIN @sales s ON i.sku = s.sku
    GROUP BY i.product, i.stock"
   :data `((sales . ,sales))))</pre>
</td><td>
<pre lang="elisp">(((product . "Widget")
  (sold . 15)
  (remaining . 35))
 ((product . "Gizmo")
  (sold . 20)
  (remaining . 55)))</pre>
</td></tr></table>
#+end_html

Join a remote Parquet file with local Elisp data:
#+begin_src elisp :results code
 (let ((airports '(((code . "JFK")
                   (name . "JFK International"))
                  ((code . "LGA")
                   (name . "LaGuardia")))))
  (duckdb-query
   "SELECT a.name,
           COUNT(*) as departures,
           ROUND(AVG(f.dep_delay), 1) as avg_delay
    FROM 'https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet' as f
    JOIN @airports a ON f.origin = a.code
    GROUP BY a.name
    ORDER BY departures DESC"
   :data `((airports . ,airports))))

;; => (((name . "JFK International") (departures . 111279) (avg_delay . 12.1))
;;     ((name . "LaGuardia") (departures . 104662) (avg_delay . 10.3)))
#+end_src

* Output Formats
:PROPERTIES:
:CUSTOM_ID: output-formats
:END:

The ~:format~ parameter controls result structure:

| Format       | Structure                 | Use Case                      |
|--------------+---------------------------+-------------------------------|
| ~:alist~     | List of alists            | General Elisp processing      |
| ~:plist~     | List of plists            | Keyword-based access          |
| ~:hash~      | List of hash-tables       | O(1) field lookup             |
| ~:vector~    | Vector of alists          | Index-based access            |
| ~:columnar~  | Alist of column vectors   | Numerical analysis            |
| ~:org-table~ | List of lists with header | Display, org-mode integration |
| ~:raw~       | JSON string               | Custom parsing                |

* Schema Introspection
:PROPERTIES:
:CUSTOM_ID: schema-introspection
:END:
Discover structure before querying:

#+begin_src elisp :results code :exports both
(duckdb-query-column-types "SELECT 1 as id, 'text' as name, 3.14 as value")
;; => (("id" . "INTEGER") ("name" . "VARCHAR") ("value" . "DECIMAL(3,2)"))
#+end_src

#+begin_src elisp :results code :exports both
(duckdb-query-columns
 "https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet")

;; => ("year" "month" "day" "dep_time" "sched_dep_time" "dep_delay" "arr_time"
;;     "sched_arr_time" "arr_delay" "carrier" "flight" "tailnum" "origin" "dest"
;;     "air_time" "distance" "hour" "minute" "time_hour")
#+end_src

* Database Persistence
:PROPERTIES:
:CUSTOM_ID: database-persistence
:END:
For workflows requiring state across queries, bind a database file:

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">(duckdb-with-transient-database
  (duckdb-query
   "CREATE TABLE events (id INT, name TEXT)"
   :readonly nil)
  (duckdb-query
   "INSERT INTO events VALUES
    (1, 'click'), (2, 'scroll')"
   :readonly nil)
  (duckdb-query "SELECT * FROM events"))</pre>
</td><td>
<pre lang="elisp">(((id . 1) (name . "click"))
 ((id . 2) (name . "scroll")))</pre>
</td></tr></table>
#+end_html

~duckdb-query-with-transient-database~ creates a temporary file deleted after the
block. Use ~duckdb-query-with-database~ for persistent files:

#+begin_src elisp
(duckdb-query-with-database "analytics.db"
  (duckdb-query "SELECT COUNT(*) FROM events"))
#+end_src

These macros work with CLI execution. For persistent processes with lower
latency, see "Session-Based Execution" below.

* (NEW) Session-Based Execution
:PROPERTIES:
:CUSTOM_ID: new-session-based-execution
:END:

For repeated queries or workflows requiring persistent state, sessions eliminate
DuckDB process spawn overhead (~10-20ms per query). A session maintains a
long-running DuckDB process with its own temporary database:

#+begin_src elisp :results code
;; first we initialize the sessions
(duckdb-query-session-start "work")
(duckdb-query-session-start "other-session")

(let ((result-set
       (list :work-results
             ;;we can now connect to the "work" session and execute queries iside of it
             (duckdb-query-with-session "work"
               (duckdb-query "CREATE TABLE events AS SELECT i, random() AS value FROM range(1000) t(i)")
               (duckdb-query "SELECT AVG(value) as average FROM events"))
             :other-results
             ;;then we can execute queries on the "other-session"
             (duckdb-query-with-session "other-session"
               (duckdb-query "CREATE TABLE logs AS SELECT i, random() AS value FROM range(10) t(i)")
               (duckdb-query "SELECT AVG(value) as average FROM logs"))
             :back-to-work
             ;;since we haven't killed "work" session process, we can go back and execute on it again
             (duckdb-query-with-session "work"
               (duckdb-query "CREATE TABLE new_table AS SELECT i, random() AS value FROM range(100) t(i)")
               (duckdb-query "SELECT AVG(value) as average FROM new_table")))))

  ;; when we're done we delete the sessions
  (duckdb-query-session-kill "work")
  (duckdb-query-session-kill "other-session")
  result-set)
#+end_src

#+begin_src elisp
(:work-results (((average . 0.4798298225990715)))
 :other-results (((average . 0.49212970609599005)))
 :back-to-work (((average . 0.4934245134851129))))
#+end_src

For temporary sessions that clean up automatically:

#+begin_src elisp :results code
(duckdb-query-with-transient-session
  (duckdb-query "CREATE TABLE scratch AS SELECT random() as val FROM range(5)")
  (duckdb-query "SELECT AVG(val) as mean FROM scratch"))
;; => (((mean . 0.33628298988435995)))
#+end_src

Sessions provide 7-10x speedup for simple queries:

| Executor | Simple Query | 10k Rows |
|----------+--------------+----------|
| :cli     | ~22ms        | ~93ms    |
| :session | ~2ms         | ~20ms    |

** Attaching External Databases

Attach external database files to a session for cross-database queries:

#+begin_src elisp :results code
(duckdb-query-session-start "analysis")
(unwind-protect
    (duckdb-query-with-session "analysis"
      ;; Attach returns the alias (derived from filename)
      (let ((alias (duckdb-query-session-attach "analysis" "/data/sales.db")))
        (duckdb-query
         (format "SELECT * FROM %s.orders LIMIT 5" alias))))
  (duckdb-query-session-kill "analysis"))
#+end_src

Use ~duckdb-query-with-database~ for scoped attachment with automatic cleanup:

#+begin_src elisp :results code
(duckdb-query-session-start "work")
(unwind-protect
    (duckdb-query-with-session "work"
      (duckdb-query "CREATE TABLE local_data AS SELECT 1 as id")
      (duckdb-query-with-database "/data/reference.db"
        ;; reference.db attached as "reference" within this scope
        (duckdb-query
         "SELECT l.id, r.name
          FROM local_data l
          JOIN reference.lookup r ON l.id = r.id"))
      ;; reference.db automatically detached here
      (duckdb-query "SELECT * FROM local_data"))
  (duckdb-query-session-kill "work"))
#+end_src

** Session Management

List active sessions:
#+begin_src elisp
(duckdb-query-session-list)
;; => (#s(duckdb-session :name "analytics" :status active :query-count 42 ...))
#+end_src

Interactive commands:
- ~M-x duckdb-query-session-display-status~ - Show all sessions with statistics
- ~M-x duckdb-query-session-kill-interactive~ - Kill session with completion
- ~M-x duckdb-query-session-kill-all~ - Kill all sessions

Session initialization commands run when sessions start:
#+begin_src elisp
(setq duckdb-query-session-init-commands
      '("SET memory_limit = '4GB'"
        "INSTALL spatial"
        "LOAD spatial"))
#+end_src
* Nested Types
:PROPERTIES:
:CUSTOM_ID: nested-types
:END:

DuckDB supports STRUCT, LIST, MAP, and ARRAY types. These serialize correctly as
nested Elisp structures:

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">(duckdb-query
 "SELECT
    {'x': 1, 'y': 2}::STRUCT(x INT, y INT)
    as point")
</pre>
</td><td>
<pre lang="elisp">(((point (x . 1) (y . 2))))</pre>
</td></tr>
<tr><td>
<pre lang="elisp">;; Nested data survives roundtrips
(let ((data
       '(((id . 1) (loc (x . 10) (y . 20)))
         ((id . 2) (loc (x . 30) (y . 40))))))
  (duckdb-query
   "SELECT id, loc.x + loc.y as sum
    FROM @data"
   :data data))</pre>
</td><td>
<pre lang="elisp">(((id . 1) (sum . 30))
 ((id . 2) (sum . 70)))</pre>
</td></tr></table>
#+end_html

* Performance
:PROPERTIES:
:CUSTOM_ID: performance
:END:

The package writes results to temporary files by default, providing 3-5x speedup
on large results compared to streaming through stdout:

: | Result Size | Default (file) | Streaming (pipe) | Speedup |
: |-------------+----------------+------------------+---------|
: | 10k rows    | 64ms           | 162ms            | 2.5x    |
: | 100k rows   | 366ms          | 1.28s            | 3.5x    |
: | 500k rows   | 1.32s          | 6.19s            | 4.7x    |

Force streaming mode with ~:output-via :pipe~ when needed. DDL statements
automatically use streaming since they cannot be wrapped in file output.

Profile your specific queries with the benchmark module:

#+begin_html
<table align="center"><tr>
    <th width="500px">Code</th>
    <th width="500px">Result</th></tr>
<tr><td>
<pre lang="elisp">(duckdb-query-bench-output-strategies
 "SELECT * FROM range(10000) t(i)"
 :iterations 3)</pre>
</td><td>
<pre>,| strategy | mean  | min   | max   | n |
,|----------|-------|-------|-------|---|
,| :file    | 22ms  | 21ms  | 23ms  | 3 |
,| :pipe    | 28ms  | 27ms  | 29ms  | 3 |
,| :speedup | 1.27x |       |       |   |</pre>
</td></tr></table>
#+end_html

Other benchmark functions: ~duckdb-query-bench-formats~ (compare output formats),
~duckdb-query-bench-nested-types~ (compare nested type handling),
~duckdb-query-bench-data-formats~ (compare ~:data~ serialization).

* Acknowledgements
:PROPERTIES:
:CUSTOM_ID: acknowledgements
:END:

- [[https://github.com/ak-coram/cl-duckdb][cl-duckdb]] by Ákos Kiss: The Common Lisp DuckDB wrapper that inspired this
  package's design philosophy. The approach of treating query results as native
  Lisp data structures, the ~with-static-table~ pattern for querying Lisp data
  directly, and the ~with-transient-connection~ / ~with-default-connection~
  macros for database context management all informed the design of
  duckdb-query's ~:data~ parameter, ~@org:~ references, and
  ~duckdb-query-with-transient-database~ / ~duckdb-query-with-database~ forms.

* Related Packages
:PROPERTIES:
:CUSTOM_ID: related-packages
:END:

- [[https://github.com/jhinch/ob-duckdb][ob-duckdb]]: Org Babel integration for DuckDB source blocks. SOON I'll add most
  of the functionalities here to it via a specialized ob-duckdb-query executor,
  this will allow org-table reference in duckdb-sql source blocks and new output
  types.
* Integration
:PROPERTIES:
:CUSTOM_ID: integration
:END:

#+begin_quote
[!WARNING]
UNDER CONSTRUCTION
#+end_quote

As mentioned before, sessions allow low-latency, fast response times, going as
low as 2ms on frequent, repeating small queries like batched updates/inserts and
single row extraction. Add to this persistent session processes that can
communicate between each other via database ~ATTACH~/~DETACH~ or external file
output/input, and we have the *foundation for database-backed major modes, worker
pools, and orchestrated data pipelines within Emacs.*


** Buffer-Local Sessions

The ~duckdb-query-session-setup-buffer~ helper attaches a session to the current
buffer. It creates the session if needed, registers the buffer as an owner, and
sets up the buffer-local binding so all ~duckdb-query~ calls within that buffer
automatically route to the session. The session persists while any owning buffer
exists and is killed when the last owner closes:

#+begin_src elisp
(add-hook 'my-data-mode-hook
          (lambda ()
            (duckdb-query-session-setup-buffer "my-data-session")))
;; All my-data-mode buffers share one session
;; Session killed when last my-data-mode buffer closes
#+end_src

This pattern enables major modes that maintain persistent analytical state. A
dashboard mode might cache expensive aggregations in session tables and refresh
instantly on demand:

#+begin_src elisp
(define-derived-mode my-dashboard-mode special-mode "Dashboard"
  (duckdb-query-session-setup-buffer "dashboard")
  (setq-local revert-buffer-function #'my-dashboard-refresh))

(defun my-dashboard-refresh (&rest _)
  "Refresh dashboard from session's cached aggregations."
  (let ((data (duckdb-query "SELECT * FROM cached_metrics")))
    (my-dashboard-render data)))
#+end_src

** Lifecycle Hooks

Three hooks provide visibility into session activity, enabling logging, metrics
collection, and cross-session coordination:

#+begin_src elisp
;; Log all queries with timing
(add-hook 'duckdb-query-session-query-executed-functions
          (lambda (name query duration-ms)
            (message "[%s] %.1fms: %s"
                     name duration-ms
                     (truncate-string-to-width query 60))))

;; Track session lifecycle
(add-hook 'duckdb-query-session-created-functions
          (lambda (name _session)
            (message "Session started: %s" name)))

(add-hook 'duckdb-query-session-killed-functions
          (lambda (name)
            (message "Session ended: %s" name)))
#+end_src

These hooks will be essential for building a coordinator layer that manages
worker sessions, tracks query performance across the system, and handles
failover when sessions die unexpectedly.

** Future Directions

This infrastructure opens up architectural patterns that go beyond single-query
workflows. The ultimate goal is to enable the creation of data-centric emacs
packages and tools, such as:

- quickly retrieving tabular data from most filetypes or complex queries
- perform tens to hundreds of CRUD operations per second
- manage and orchestrate data processing jobs across multiple workers from a central coordinator
- leverage [[https://github.com/cwida/duckpgq-extension][graph queries]], [[https://github.com/duckdb/duckdb-spatial][geo-spatial processing]], [[https://github.com/duckdb/duckdb-vss][vector similarity search]] and other techniques inside Emacs

Some directions still in design:

- *Database-backed buffers*: Major modes where buffer content is backed by
  session tables, enabling SQL-powered search, filter, and transform operations
  that would be impractical with pure Elisp
- *Worker pools*: Multiple sessions processing jobs in parallel, coordinated
  through a shared database via ~ATTACH~ or message-passing through elisp.
- *Live dashboards*: Buffers that subscribe to query results and refresh
  automatically when underlying data changes

I'll update this section as these experiments mature into usable packages.
